---
name: Реализация автоматического сбора требований с остановкой модели
overview: ""
todos:
  - id: 1c2588c4-fe2d-41be-af1e-f2de6fb11851
    content: Проверить документацию GigaChat API на поддержку stop_sequences и других параметров остановки
    status: pending
  - id: 9d609a4e-9694-46b9-8ca5-7abf2e666665
    content: Модифицировать ChatWithJSON для приема и передачи истории сообщений в API
    status: pending
  - id: 22af4c87-bee3-4c91-be81-712bb4175b05
    content: Добавить загрузку истории сообщений из БД в ChatHandler перед отправкой в API
    status: pending
  - id: 7183f2c5-0771-437c-9745-36c537713e3e
    content: Создать новый endpoint /api/chat/collect для режима автоматического сбора требований
    status: pending
  - id: 3069df34-9a7b-4583-a6e9-41cc425c8824
    content: Реализовать генератор system prompt на основе списка обязательных вопросов
    status: pending
  - id: 52ca470c-fb67-432a-9232-52cbe5a460d9
    content: Добавить парсинг JSON-ответов для определения статуса (collecting/ready)
    status: pending
  - id: 31a0e03b-81cd-4a51-aa81-b3aa6ca1f3b2
    content: Реализовать автоматический цикл вопрос-ответ с остановкой при готовности
    status: pending
  - id: d80fc6d9-e785-47fa-bfa5-e858ab9c358c
    content: Добавить UI для настройки обязательных вопросов и отображения процесса сбора
    status: pending
---

# Реализация автоматического сбора требований с остановкой модели

## Анализ текущей реализации

Текущий код:

- История сообщений хранится в БД, но **не передается** в API GigaChat
- Каждый запрос отправляет только одно новое сообщение без контекста
- Есть поддержка system prompt через `JSONConfig`
- Поле `FinishReason` в ответах API не используется
- Поддержка JSON-формата ответов уже реализована

## Варианты решения

### Вариант 1: Системный промпт + История сообщений (Рекомендуемый)

**Принцип работы:**

- В system prompt описывается роль модели и список обязательных вопросов
- При каждом запросе передается полная история сообщений сессии
- Модель задает вопросы по одному, пока не получит все ответы
- Когда все вопросы заданы - модель выдает финальный результат

**Изменения:**

1. Модифицировать `ChatWithJSON` в [backend/gigachat/client.go](backend/gigachat/client.go) для приема истории сообщений
2. В `ChatHandler` загружать историю из БД и передавать в API
3. Добавить новый endpoint `/api/chat/collect` для режима сбора требований
4. Добавить конфигурацию system prompt с описанием обязательных вопросов

**Преимущества:**

- Не требует изменений в API GigaChat
- Работает через промпт-инжиниринг
- Модель сама решает, когда остановиться

**Недостатки:**

- Зависит от качества промпта
- Может потребоваться несколько итераций для настройки

### Вариант 2: Stop Sequences + JSON маркеры

**Принцип работы:**

- Модель возвращает JSON с полем `status: "collecting"` или `status: "ready"`
- В system prompt указывается стоп-слово (например, `[RESULT_READY]`)
- При получении стоп-слова или `status: "ready"` - останавливаем диалог
- Финальный результат в поле `result` JSON-ответа

**Изменения:**

1. Расширить `JSONConfig` для поддержки stop sequences
2. Добавить поле `StopSequences []string` в `ChatRequest`
3. Отслеживать finish_reason и содержимое ответа для определения остановки
4. Парсить JSON-ответ для проверки статуса готовности

**Преимущества:**

- Более надежный контроль остановки
- Структурированный формат ответа

**Недостатки:**

- Требует поддержки stop sequences в API (нужно проверить)
- Сложнее в реализации

### Вариант 3: Комбинированный подход

**Принцип работы:**

- System prompt с описанием обязательных вопросов
- История сообщений для контекста
- JSON-формат ответа с полями: `question`, `status`, `result`
- Отслеживание `finish_reason` и содержимого ответа

**Структура JSON-ответа:**

```json
{
  "question": "Как называется приложение?",
  "status": "collecting",
  "collected": ["name", "package"],
  "remaining": ["technologies", "platform"]
}
```

Когда `status: "ready"`:

```json
{
  "status": "ready",
  "result": "Готовое ТЗ..."
}
```

**Изменения:**

1. Все изменения из Варианта 1
2. Расширенный JSON schema для структурированного ответа
3. Логика парсинга и проверки статуса на бэкенде
4. Автоматическое продолжение диалога при `status: "collecting"`

**Преимущества:**

- Максимальная надежность
- Полный контроль процесса
- Структурированные данные

**Недостатки:**

- Наиболее сложная реализация
- Требует больше кода

## Рекомендуемый план реализации

### Этап 1: Базовая инфраструктура

1. Модифицировать `ChatWithJSON` для приема истории сообщений
2. Загружать историю из БД в `ChatHandler` и передавать в API
3. Добавить структуру для конфигурации режима сбора требований

### Этап 2: Новый endpoint для режима сбора

1. Создать `/api/chat/collect` endpoint
2. Принимать конфигурацию с обязательными вопросами
3. Генерировать system prompt на основе конфигурации
4. Реализовать автоматический цикл вопрос-ответ

### Этап 3: Определение готовности результата

1. Парсить JSON-ответ для проверки статуса
2. Отслеживать finish_reason
3. Останавливать диалог при получении финального результата

### Этап 4: Фронтенд интеграция

1. Добавить UI для настройки обязательных вопросов
2. Отображать процесс сбора информации
3. Показывать финальный результат отдельно

## Файлы для изменения

- [backend/gigachat/client.go](backend/gigachat/client.go) - добавить поддержку истории сообщений
- [backend/api/chat.go](backend/api/chat.go) - загрузка истории и новый endpoint
- [backend/api/collect.go](backend/api/collect.go) - новый файл для режима сбора (если нужен отдельный handler)
- [frontend/src/lib/api.ts](frontend/src/lib/api.ts) - новый метод для режима сбора
- [frontend/src/App.svelte](frontend/src/App.svelte) - UI для настройки и отображения

## Вопросы для уточнения

1. Какой вариант предпочтителен: 1, 2 или 3?
2. Нужен ли отдельный endpoint `/api/chat/collect` или расширить существующий `/api/chat`?
3. Должен ли процесс быть полностью автоматическим (без участия пользователя) или с подтверждением каждого ответа?
4. Какой формат финального результата: JSON, Markdown или обычный текст?